{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install evaluate requests ultralytics supervision","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport shutil\n\nimport torch\nimport numpy as np\nimport pandas as pd\nimport random\n/\nfrom transformers import (\n    AutoImageProcessor, AutoModelForImageClassification,\n    AutoModelForObjectDetection, ImageClassificationPipeline,\n    TrainingArguments, Trainer, pipeline\n)\n\nfrom transformers.image_utils import load_image\nimport evaluate\nfrom datasets import load_dataset\n\nfrom matplotlib import pyplot as plt\nimport matplotlib.patches as patches\nfrom PIL import Image\n\nfrom requests import get\nfrom huggingface_hub import hf_hub_download\n\nfrom ultralytics import YOLO\nfrom supervision import Detections\n\nfrom datasets import Dataset, DatasetDict, load_metric\nfrom sklearn.model_selection import train_test_split\n\n# skimage\nfrom skimage.io import imshow, imread, imsave\nfrom skimage.transform import rotate, AffineTransform, warp,rescale, resize, downscale_local_mean\nfrom skimage import color,data\nfrom skimage.exposure import adjust_gamma\nfrom skimage.util import random_noise","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Sorting","metadata":{}},{"cell_type":"code","source":"# Чтение данных из файла default.txt\nfile_path = \"/kaggle/input/aminfins/default.txt\"\nwith open(file_path, \"r\") as file:\n    lines = file.readlines()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sorted_data = sorted(lines, key=lambda x: int(x.split()[-1]))","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Write the sorted paths to a text file\nwith open('sorted_paths.txt', 'w') as f:\n    for path in sorted_data:\n        f.write(path.replace('\\n', ''))  # Remove the newline character\n        f.write('\\n')  # Add a newline after each path","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the output directory relative to the notebook's working directory\noutput_dir = '/kaggle/working/'\n\n# Create directories 0, 1, 2 if they don't exist\nfor i in range(3):\n    directory = os.path.join(output_dir, str(i))\n    if not os.path.exists(directory):\n        os.makedirs(directory)\n\n# Move photos to respective folders\nfor item in sorted_data:\n    photo_path, digit = item.split()\n    filename = os.path.basename(photo_path.strip())\n    digit = digit.strip()\n    destination_folder = os.path.join(output_dir, digit)\n    destination_path = os.path.join(destination_folder, filename)\n    # Construct full source path assuming the photos are in \"/kaggle/input/aminfins/All images\"\n    source_path = os.path.join(\"/kaggle/input/aminfins/All images\", filename)\n    shutil.copy(source_path, destination_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shutil.make_archive('/kaggle/working/0', 'zip', '/kaggle/working/0')\nshutil.make_archive('/kaggle/working/1', 'zip', '/kaggle/working/1')\nshutil.make_archive('/kaggle/working/2', 'zip', '/kaggle/working/2')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Reading","metadata":{}},{"cell_type":"code","source":"# Функция загрузки изображения в формате Pillow\ndef load_image_(image_path, label):\n    return Image.open('/kaggle/input/aminfins/gaz_sorted_images/' + label + image_path)\n\n# Чтение данных из файла sorted_paths.txt\nfile_path = \"/kaggle/input/aminfins/sorted_paths.txt\"\nwith open(file_path, \"r\") as file:\n    lines = file.readlines()\n\n# Создание списков для хранения данных\nimage_paths = []\nlabels = []\n\n# Разделение строк на пути к изображениям и метки\nfor line in lines:\n    parts = line.split()\n    image_paths.append(parts[0])\n    labels.append(int(parts[1]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Загрузка изображений в формате Pillow для разных меток\nneutral_images = [load_image_(path, label_mapping[label] + '/') for path, label in zip(image_paths, labels) if label == 0]\nmicrosleep_images = [load_image_(path, label_mapping[label] + '/') for path, label in zip(image_paths, labels) if label == 1]\nyawning_images = [load_image_(path, label_mapping[label] + '/') for path, label in zip(image_paths, labels) if label == 2]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Augmentation","metadata":{}},{"cell_type":"code","source":"neutral_images_arr = [np.array(image) for image in neutral_images]\nmicrosleep_images_arr = [np.array(image) for image in microsleep_images]\nyawning_images_arr = [np.array(image) for image in yawning_images]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def apply_transformations_and_convert(arrays_list):\n    transformed_pillow_images = []\n    \n    for array in arrays_list:\n        # Convert array to Pillow image\n        original_pillow_image = Image.fromarray(array.astype('uint8'))  # Convert to uint8\n        transformed_pillow_images.append(original_pillow_image)\n        \n        # Horizontally flipped\n        hflipped_array = np.fliplr(array)\n        hflipped_pillow_image = Image.fromarray(hflipped_array.astype('uint8'))  # Convert to uint8\n        transformed_pillow_images.append(hflipped_pillow_image)\n        \n        # Vertically flipped\n        vflipped_array = np.flipud(array)\n        vflipped_pillow_image = Image.fromarray(vflipped_array.astype('uint8'))  # Convert to uint8\n        transformed_pillow_images.append(vflipped_pillow_image)\n        \n        # Clockwise rotation by 30 degrees\n        rot_30_clockwise_array = rotate(array, angle=30)\n        rot_30_clockwise_pillow_image = Image.fromarray((rot_30_clockwise_array * 255).astype('uint8'))  # Convert to uint8\n        transformed_pillow_images.append(rot_30_clockwise_pillow_image)\n        \n        # Anticlockwise rotation by 30 degrees\n        rot_30_anticlockwise_array = rotate(array, angle=-30)\n        rot_30_anticlockwise_pillow_image = Image.fromarray((rot_30_anticlockwise_array * 255).astype('uint8'))  # Convert to uint8\n        transformed_pillow_images.append(rot_30_anticlockwise_pillow_image)\n        \n        # Clockwise rotation by 45 degrees\n        rot_45_clockwise_array = rotate(array, angle=45)\n        rot_45_clockwise_pillow_image = Image.fromarray((rot_45_clockwise_array * 255).astype('uint8'))  # Convert to uint8\n        transformed_pillow_images.append(rot_45_clockwise_pillow_image)\n        \n        # Anticlockwise rotation by 45 degrees\n        rot_45_anticlockwise_array = rotate(array, angle=-45)\n        rot_45_anticlockwise_pillow_image = Image.fromarray((rot_45_anticlockwise_array * 255).astype('uint8'))  # Convert to uint8\n        transformed_pillow_images.append(rot_45_anticlockwise_pillow_image)\n        \n        # Clockwise rotation by 60 degrees\n        rot_60_clockwise_array = rotate(array, angle=60)\n        rot_60_clockwise_pillow_image = Image.fromarray((rot_60_clockwise_array * 255).astype('uint8'))  # Convert to uint8\n        transformed_pillow_images.append(rot_60_clockwise_pillow_image)\n        \n        # Anticlockwise rotation by 60 degrees\n        rot_60_anticlockwise_array = rotate(array, angle=-60)\n        rot_60_anticlockwise_pillow_image = Image.fromarray((rot_60_anticlockwise_array * 255).astype('uint8'))  # Convert to uint8\n        transformed_pillow_images.append(rot_60_anticlockwise_pillow_image)\n        \n        # Brightness adjusted array (gamma=0.5)\n        array_bright = adjust_gamma(array, gamma=0.5, gain=1)\n        bright_pillow_image = Image.fromarray(array_bright.astype('uint8'))  # Convert to uint8\n        transformed_pillow_images.append(bright_pillow_image)\n        \n        # Darkened array (gamma=2)\n        array_dark = adjust_gamma(array, gamma=2, gain=1)\n        dark_pillow_image = Image.fromarray(array_dark.astype('uint8'))  # Convert to uint8\n        transformed_pillow_images.append(dark_pillow_image)\n        \n        # Noisy array\n        noisy_array = random_noise(array)\n        noisy_pillow_image = Image.fromarray((noisy_array * 255).astype('uint8'))  # Convert to uint8\n        transformed_pillow_images.append(noisy_pillow_image)\n        \n    return transformed_pillow_images","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"neutral_aug = apply_transformations_and_convert(neutral_images_arr)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the output directory\noutput_directory = \"/kaggle/working/neutral_aug\"\n\n# Create the output directory if it doesn't exist\nos.makedirs(output_directory, exist_ok=True)\n\nfor i, image in enumerate(neutral_aug):\n    image_path = os.path.join(output_directory, f\"image_{i}.jpg\")\n    image.save(image_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Define the directory containing the images\n# directory = \"/kaggle/working/neutral_aug\"\n\n# # Iterate over each file in the directory\n# for filename in os.listdir(directory):\n#     # Construct the full file path\n#     file_path = os.path.join(directory, filename)\n    \n#     # Check if the file is a regular file (not a directory)\n#     if os.path.isfile(file_path):\n#         # Remove the file\n#         os.remove(file_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"microsleep_aug = apply_transformations_and_convert(microsleep_images_arr)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the output directory\noutput_directory = \"/kaggle/working/microsleep_aug\"\n\n# Create the output directory if it doesn't exist\nos.makedirs(output_directory, exist_ok=True)\n\nfor i, image in enumerate(microsleep_aug):\n    image_path = os.path.join(output_directory, f\"image_{i}.jpg\")\n    image.save(image_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yawning_aug = apply_transformations_and_convert(yawning_images_arr)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the output directory\noutput_directory = \"/kaggle/working/yawning_aug\"\n\n# Create the output directory if it doesn't exist\nos.makedirs(output_directory, exist_ok=True)\n\nfor i, image in enumerate(yawning_aug):\n    image_path = os.path.join(output_directory, f\"image_{i}.jpg\")\n    image.save(image_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the directories to be zipped\ndirectories = [\"/kaggle/working/neutral_aug\", \"/kaggle/working/microsleep_aug\", \"/kaggle/working/yawning_aug\"]\n\n# Zip each directory\nfor directory in directories:\n    shutil.make_archive(directory, 'zip', directory)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Aug Data Reading","metadata":{}},{"cell_type":"code","source":"# Словарь для преобразования числовых меток в строковые\nlabel_mapping = {\n    0: \"neutral\",\n    1: \"microsleep\",\n    2: \"yawning\",\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Directory containing the images\ndirectory = '/kaggle/input/aminfins/gaz_aug_zip/neutral_aug/'\n\n# Create a list to store PIL images\nneutral_images_new = []\n\n# Iterate over all files in the directory\nfor filename in os.listdir(directory):\n\n        # Construct the full path to the image file\n        file_path = os.path.join(directory, filename)\n        # Open the image file as a PIL image and append it to the list\n        pil_image = Image.open(file_path)\n        neutral_images_new.append(pil_image)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Directory containing the images\ndirectory = '/kaggle/input/aminfins/gaz_aug_zip/microsleep_aug/'\n\n# Create a list to store PIL images\nmicrosleep_images_new = []\n\n# Iterate over all files in the directory\nfor filename in os.listdir(directory):\n\n        # Construct the full path to the image file\n        file_path = os.path.join(directory, filename)\n        # Open the image file as a PIL image and append it to the list\n        pil_image = Image.open(file_path)\n        microsleep_images_new.append(pil_image)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Directory containing the images\ndirectory = '/kaggle/input/aminfins/gaz_aug_zip/yawning_aug/'\n\n# Create a list to store PIL images\nyawning_images_new = []\n\n# Iterate over all files in the directory\nfor filename in os.listdir(directory):\n\n        # Construct the full path to the image file\n        file_path = os.path.join(directory, filename)\n        # Open the image file as a PIL image and append it to the list\n        pil_image = Image.open(file_path)\n        yawning_images_new.append(pil_image)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"neutral_labels = [0] * len(neutral_images_new)\nmicrosleep_labels = [1] * len(microsleep_images_new)\nyawning_labels = [2] * len(yawning_images_new)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_images = neutral_images_new + microsleep_images_new + yawning_images_new\nall_labels = neutral_labels + microsleep_labels + yawning_labels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Разделение данных на тренировочную и тестовую выборку\ntrain_images, test_images, train_labels, test_labels = train_test_split(\n    all_images, all_labels, test_size=0.15, random_state=0)\n\n# Создание объектов Dataset для тренировочной и тестовой выборок\ntrain_dataset = Dataset.from_dict({\"image\": train_images, \"label\": train_labels})\ntest_dataset = Dataset.from_dict({\"image\": test_images, \"label\": test_labels})\n\n# Создание объекта DatasetDict\ndataset = DatasetDict({\"train\": train_dataset, \"test\": test_dataset})\n\n# Вывод информации о DatasetDict\nprint(dataset)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metric = load_metric(\"accuracy\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"example = dataset[\"train\"][122]\nexample['image']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"id2label = label_mapping\nlabel2id = {v: k for k, v in id2label.items()}\nid2label, label2id","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_checkpoint = \"microsoft/resnet-50\"\nbatch_size = 8\nimage_processor  = AutoImageProcessor.from_pretrained(model_checkpoint)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchvision.transforms import (\n    CenterCrop,\n    Compose,\n    Normalize,\n    RandomHorizontalFlip,\n    RandomResizedCrop,\n    Resize,\n    ToTensor,\n)\n\nnormalize = Normalize(mean=image_processor.image_mean, std=image_processor.image_std)\nif \"height\" in image_processor.size:\n    size = (image_processor.size[\"height\"], image_processor.size[\"width\"])\n    crop_size = size\n    max_size = None\nelif \"shortest_edge\" in image_processor.size:\n    size = image_processor.size[\"shortest_edge\"]\n    crop_size = (size, size)\n    max_size = image_processor.size.get(\"longest_edge\")\n\ntrain_transforms = Compose(\n        [\n            RandomResizedCrop(crop_size),\n            RandomHorizontalFlip(),\n            ToTensor(),\n            normalize,\n        ]\n    )\n\nval_transforms = Compose(\n        [\n            Resize(size),\n            CenterCrop(crop_size),\n            ToTensor(),\n            normalize,\n        ]\n    )\n\ndef preprocess_train(example_batch):\n    \"\"\"Apply train_transforms across a batch.\"\"\"\n    example_batch[\"pixel_values\"] = [\n        train_transforms(image.convert(\"RGB\")) for image in example_batch[\"image\"]\n    ]\n    return example_batch\n\ndef preprocess_val(example_batch):\n    \"\"\"Apply val_transforms across a batch.\"\"\"\n    example_batch[\"pixel_values\"] = [val_transforms(image.convert(\"RGB\")) for image in example_batch[\"image\"]]\n    return example_batch","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds = dataset['train']\nval_ds = dataset['test']\n\ntrain_ds.set_transform(preprocess_train)\nval_ds.set_transform(preprocess_val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForImageClassification.from_pretrained(\n    model_checkpoint, \n    label2id=label2id,\n    id2label=id2label,\n    ignore_mismatched_sizes = True,\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# the compute_metrics function takes a Named Tuple as input:\n# predictions, which are the logits of the model as Numpy arrays,\n# and label_ids, which are the ground-truth labels as Numpy arrays.\ndef compute_metrics(eval_pred):\n    \"\"\"Computes accuracy on a batch of predictions\"\"\"\n    predictions = np.argmax(eval_pred.predictions, axis=1)\n    return metric.compute(predictions=predictions, references=eval_pred.label_ids)\n\ndef collate_fn(examples):\n    pixel_values = torch.stack([example[\"pixel_values\"] for example in examples])\n    labels = torch.tensor([example[\"label\"] for example in examples])\n    return {\"pixel_values\": pixel_values, \"labels\": labels}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"args = TrainingArguments(\n    \"train_image_kabyte\",\n    remove_unused_columns=False,\n    evaluation_strategy = \"epoch\",\n    save_strategy = \"epoch\",\n    num_train_epochs=5,\n    save_steps=200\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n    model,\n    args,\n    train_dataset=train_ds,\n    eval_dataset=val_ds,\n    tokenizer=image_processor,\n    compute_metrics=compute_metrics,\n    data_collator=collate_fn,\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_results = trainer.train()\n# rest is optional but nice to have\ntrainer.save_model()\ntrainer.log_metrics(\"train\", train_results.metrics)\ntrainer.save_metrics(\"train\", train_results.metrics)\ntrainer.save_state()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"j = random.randint(0,400)\nimage = dataset['test'][j]['image']\nprint(id2label[dataset['test'][j]['label']])\nimage","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classifier = pipeline(\"image-classification\", model='/kaggle/working/train_image_kabyte/checkpoint-1555')\nprint(classifier(image)[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
